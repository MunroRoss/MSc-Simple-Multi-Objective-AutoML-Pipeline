{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fecc0d2",
   "metadata": {},
   "source": [
    "# MSc Simple Multi-Objective AutoML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a33e41f",
   "metadata": {},
   "source": [
    "First I will look at 2 sets of data, 1 binary classification and one multiclass. I will do a complete pipeline and evaluation that will later be automated. That pipeline will include:\n",
    "\n",
    "* Data Preprocessing\n",
    "* Model Training\n",
    "* Hyperparameter optimization.\n",
    "* Model Evaluation with Accuracy\n",
    "* Model Evaluation with Interpretability (specified metrics)\n",
    "* Incorporating into a ranking function for model selection\n",
    "\n",
    "Each automation will be constrained.\n",
    "\n",
    "<img src=\"images\\Pipeline.png\"/>\n",
    "\n",
    "Algorithms that will be used for modelling will be limited to:\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Decision Trees\n",
    "3. Random Forest\n",
    "4. LightGBM\n",
    "5. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b43ea5f",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "This study will assume that datasets input into the automated pipeline will be reasonably clean and representative, as commonly provided by machine learning dataset repositories. Therefore extensive data cleaning and feature engineering are considered outside the scope of this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed951fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Import the algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a8cce9",
   "metadata": {},
   "source": [
    "Telco Customer Churn:\n",
    "\n",
    "https://www.kaggle.com/datasets/blastchar/telco-customer-churn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd3e714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "churn_data = pd.read_csv(\"Datasets/Telco-Customer-Churn.csv\")\n",
    "print(type(churn_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145d80db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the dataframe\n",
    "churn_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95a6b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Inspect the datatype of each feature and if there are any missing values\n",
    "churn_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43ac4c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "      <td>7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7043</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6531</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>3555</td>\n",
       "      <td>3641</td>\n",
       "      <td>4933</td>\n",
       "      <td>6361</td>\n",
       "      <td>3390</td>\n",
       "      <td>3096</td>\n",
       "      <td>3498</td>\n",
       "      <td>3088</td>\n",
       "      <td>3095</td>\n",
       "      <td>3473</td>\n",
       "      <td>2810</td>\n",
       "      <td>2785</td>\n",
       "      <td>3875</td>\n",
       "      <td>4171</td>\n",
       "      <td>2365</td>\n",
       "      <td>11</td>\n",
       "      <td>5174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        customerID gender Partner Dependents PhoneService MultipleLines  \\\n",
       "count         7043   7043    7043       7043         7043          7043   \n",
       "unique        7043      2       2          2            2             3   \n",
       "top     7590-VHVEG   Male      No         No          Yes            No   \n",
       "freq             1   3555    3641       4933         6361          3390   \n",
       "\n",
       "       InternetService OnlineSecurity OnlineBackup DeviceProtection  \\\n",
       "count             7043           7043         7043             7043   \n",
       "unique               3              3            3                3   \n",
       "top        Fiber optic             No           No               No   \n",
       "freq              3096           3498         3088             3095   \n",
       "\n",
       "       TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "count         7043        7043            7043            7043   \n",
       "unique           3           3               3               3   \n",
       "top             No          No              No  Month-to-month   \n",
       "freq          3473        2810            2785            3875   \n",
       "\n",
       "       PaperlessBilling     PaymentMethod TotalCharges Churn  \n",
       "count              7043              7043         7043  7043  \n",
       "unique                2                 4         6531     2  \n",
       "top                 Yes  Electronic check                 No  \n",
       "freq               4171              2365           11  5174  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "churn_data.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff0696c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87be3a",
   "metadata": {},
   "source": [
    "Quick things to realise when inspecting the data:\n",
    "\n",
    "* The ID column will be useless in modelling and will need to be dropped consistently accross datasets, it can be seen that the **number of unique values = number of rows** therefore some logic may be implemented to decide when to drop.\n",
    "\n",
    "* The column \"TotalCharges\" has 6531 unique values, after inspection, these are numerical charge values stored as strings, in the dtype object. it would be good to process these in the pipeline.\n",
    "\n",
    "To maintain a simple and generic preprocessing pipeline, features with type object can be treated as categorical variables. It can be implemented that features with more than 20 distinct values can be dropped, as this represents high-cardinality and can negatively impact interpretability and explanation stability. No attempt will be made to coerce these features to numeric values, as this would require dataset specific cleaning logic and would defeat the point of implementing this across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "124af77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function for identifying data types of each column for preprocessing, splitting them into groups\n",
    "\n",
    "def get_feature_groups(data):\n",
    "\n",
    "    categorical_columns = data.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns #detect all categorical column labels\n",
    "    numeric_columns = data.select_dtypes(include=\"number\").columns #detect all numerical column labels \n",
    "    bool_columns = data.select_dtypes(include=\"bool\").columns #detect possible boolean columns\n",
    "\n",
    "    numeric_columns = numeric_columns.union(bool_columns).tolist() #merge boolean in with numeric as they are 0 and 1 representations\n",
    "\n",
    "    high_cardinality = data[categorical_columns].nunique() > 20 #isolate high cardinality features\n",
    "\n",
    "    #columns_to_drop = high_cardinality[high_cardinality].index.tolist() #create a column to drop list\n",
    "    categorical_columns = high_cardinality[~high_cardinality].index.tolist() #dropping high cardinality features from categorical list\n",
    "    \n",
    "    return numeric_columns, categorical_columns, #columns_to_drop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b081f7",
   "metadata": {},
   "source": [
    "By creating a list for each type of variable, this will lead into transforming the columns and preparing for a scikit learn pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "927e2c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5634, 20), (5634,), (1409, 20), (1409,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "y = churn_data[\"Churn\"]\n",
    "X = churn_data.drop(\"Churn\", axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053d38e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns, categorical_columns = get_feature_groups(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06012077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SeniorCitizen', 'tenure', 'MonthlyCharges']\n",
      "['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_columns)\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4df1fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer\n",
    "\n",
    "preprocesser = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_columns),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_columns)\n",
    "    ],\n",
    "    remainder = \"drop\",\n",
    "    n_jobs=-1 # enable use of all cpu threads locally\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a92b1ce",
   "metadata": {},
   "source": [
    "Column transformer will help to transform the numerical features and the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20fbf8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of models to iterate over\n",
    "\n",
    "models = {\n",
    "    \"logreg\": LogisticRegression(),\n",
    "    \"dt\": DecisionTreeClassifier(),\n",
    "    \"rf\": RandomForestClassifier(),\n",
    "    \"svm\": LinearSVC(),\n",
    "   # \"lgb\": lgb(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f7a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterative pipeline\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocess\", preprocesser),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    score = pipeline.score(X_test, y_test)\n",
    "\n",
    "    results[name] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77ffe5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logreg': 0.8211497515968772, 'dt': 0.7196593328601846, 'rf': 0.78708303761533, 'svm': 0.8183108587650816}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ed520",
   "metadata": {},
   "source": [
    "While the previous pipeline it clean, if cross validation is used feature selection based on X_train will cause data leakage for each fold as the validation set would have been used to make transformations on the training data. Hence we want to implement feature selection and preprocessing of data for each training fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93832a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5634, 20), (5634,), (1409, 20), (1409,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(churn_data[\"Churn\"]) # encode category labels\n",
    "X = churn_data.drop(\"Churn\", axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "610f1cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transformer class to group features in first step of a pipeline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class GroupFeatures(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    # Constructor method\n",
    "    def __init__(self, max_unique=20):\n",
    "        self.max_unique = max_unique\n",
    "\n",
    "    #Fit method learns column groupings and detects high cardinality --> metadata for future steps\n",
    "    def fit(self, X, y=None):\n",
    "        categorical = X.select_dtypes(include=[\"object\", \"string\", \"category\"])\n",
    "        numeric = X.select_dtypes(include=\"number\")\n",
    "        boolean = X.select_dtypes(include=\"bool\")\n",
    "\n",
    "        high_cardinality = categorical.nunique() > self.max_unique #Detects high cardinality above maximum value specified\n",
    "\n",
    "        self.numeric_columns_ = numeric.columns.union(boolean.columns).tolist() #Creates numerical column list\n",
    "        self.categorical_columns_ = high_cardinality[~high_cardinality].index.tolist() #Creates categorical column list - high cardinality features\n",
    "\n",
    "        self.keep_columns_ = self.numeric_columns_ + self.categorical_columns_\n",
    "\n",
    "        return self\n",
    "\n",
    "    # passes through the data untransformed \n",
    "    def transform(self, X):\n",
    "        return X[self.keep_columns_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f65d6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer for feature preprocessing\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), make_column_selector(dtype_include=\"number\")), \n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), make_column_selector(dtype_include=[\"object\", \"string\", \"category\"])),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e434b661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Cross-Validation Evaluation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"f1\": \"f1\",\n",
    "    \"roc_auc\": \"roc_auc\"\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    # Create pipeline that include GroupFeatures in first step\n",
    "    pipeline = Pipeline([\n",
    "    (\"features\", GroupFeatures(max_unique=20)),\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    cv_results = cross_validate(\n",
    "    pipeline,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    return_estimator=True\n",
    "    )\n",
    "\n",
    "    results[name] = cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "051f17ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78881988, 0.81011535, 0.78615794, 0.80834073, 0.79928952])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['logreg']['test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58433b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.1442647 , 0.06859374, 0.06281042, 0.05928993, 0.04544878]),\n",
       " 'score_time': array([0.03778338, 0.04402351, 0.04322529, 0.01792431, 0.03620172]),\n",
       " 'estimator': [Pipeline(steps=[('features', GroupFeatures()),\n",
       "                  ('preprocess',\n",
       "                   ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000251A3F00210>),\n",
       "                                                   ('cat',\n",
       "                                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000251A5CB7110>)])),\n",
       "                  ('model', LogisticRegression())]),\n",
       "  Pipeline(steps=[('features', GroupFeatures()),\n",
       "                  ('preprocess',\n",
       "                   ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000251A47CF3D0>),\n",
       "                                                   ('cat',\n",
       "                                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000251A49A94D0>)])),\n",
       "                  ('model', LogisticRegression())]),\n",
       "  Pipeline(steps=[('features', GroupFeatures()),\n",
       "                  ('preprocess',\n",
       "                   ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000251A4CCC2D0>),\n",
       "                                                   ('cat',\n",
       "                                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000251A5CF7C10>)])),\n",
       "                  ('model', LogisticRegression())]),\n",
       "  Pipeline(steps=[('features', GroupFeatures()),\n",
       "                  ('preprocess',\n",
       "                   ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000251A4CB5E50>),\n",
       "                                                   ('cat',\n",
       "                                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000251A49499D0>)])),\n",
       "                  ('model', LogisticRegression())]),\n",
       "  Pipeline(steps=[('features', GroupFeatures()),\n",
       "                  ('preprocess',\n",
       "                   ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000251A2737510>),\n",
       "                                                   ('cat',\n",
       "                                                    OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                    <sklearn.compose._column_transformer.make_column_selector object at 0x00000251A5CB1A10>)])),\n",
       "                  ('model', LogisticRegression())])],\n",
       " 'test_accuracy': array([0.78881988, 0.81011535, 0.78615794, 0.80834073, 0.79928952]),\n",
       " 'test_f1': array([0.55925926, 0.60805861, 0.57345133, 0.59398496, 0.57992565]),\n",
       " 'test_roc_auc': array([0.81841444, 0.84237919, 0.83915992, 0.84112253, 0.85117259])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['logreg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca38937",
   "metadata": {},
   "source": [
    "`RandomSearchCV()` will be used for hyperparameter optimisation and a parameter space needs to be defined, for example:\n",
    "\n",
    "Logistic Regression → C, penalty\n",
    "\n",
    "Decision Tree → max_depth, min_samples_leaf\n",
    "\n",
    "Random Forest → n_estimators, max_depth\n",
    "\n",
    "XGBoost/LightGBM → max_depth, learning_rate, n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe6fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define param distributions\n",
    "\n",
    "param_grid = {\n",
    "    \"logreg\" : {},\n",
    "    \"dt\" : {},\n",
    "    \"rf\" : {},\n",
    "    \"svm\" : {},\n",
    "    \"lgb\" : {}\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
